{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('.')\n",
    "from msg3d.utils import count_params, import_class\n",
    "from msg3d.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = yaml.safe_load(open('./config/defaults.yaml', 'r'))\n",
    "config = yaml.safe_load(open('./config/conflab/train_joint.yaml', 'r'))\n",
    "config = {**defaults, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['phase'] = 'train'\n",
    "config['work_dir'] = 'transfer_learning/conflab/joint'\n",
    "config['weights'] = 'pretrained-models/kinetics-joint.pt'\n",
    "config['ignore_weights'] = ['fc.weight', 'fc.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['save_score', 'seed', 'feeder', 'num_worker', 'model_saved_name', 'checkpoint', 'start_epoch', 'num_epoch', 'optimizer', 'assume_yes', 'debug', 'print_log', 'log_interval', 'save_interval', 'eval_interval', 'eval_start', 'show_topk', 'half', 'amp_opt_level', 'work_dir', 'train_feeder_args', 'test_feeder_args', 'model', 'model_args', 'weight_decay', 'base_lr', 'step', 'device', 'batch_size', 'forward_batch_size', 'test_batch_size', 'nesterov', 'phase', 'weights', 'ignore_weights'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir transfer_learning/conflab/joint/trainlogs already exists\n",
      "Dir removed: transfer_learning/conflab/joint/trainlogs\n",
      "Cannot parse global_step from model weights filename\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 0.7825: 100%|██████████| 136/136 [01:24<00:00,  1.60it/s]\n",
      "/home/jose/.local/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:124: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n",
      "100%|██████████| 30/30 [00:33<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7526399155227033  model:  transfer_learning/conflab/joint\n",
      "ROC AUC: 0.7448915350202421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 3.4351: 100%|██████████| 136/136 [01:23<00:00,  1.63it/s]\n",
      "100%|██████████| 30/30 [00:32<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6842661034846885  model:  transfer_learning/conflab/joint\n",
      "ROC AUC: 0.6152693175232544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 0.4186: 100%|██████████| 136/136 [01:24<00:00,  1.60it/s]\n",
      "100%|██████████| 30/30 [00:40<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7196409714889124  model:  transfer_learning/conflab/joint\n",
      "ROC AUC: 0.6947044125245228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 0.8104: 100%|██████████| 136/136 [01:30<00:00,  1.50it/s]\n",
      "100%|██████████| 30/30 [01:28<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5929250263991552  model:  transfer_learning/conflab/joint\n",
      "ROC AUC: 0.7465996752416845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 0.9052: 100%|██████████| 136/136 [01:32<00:00,  1.47it/s]\n",
      "100%|██████████| 30/30 [01:24<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7360084477296727  model:  transfer_learning/conflab/joint\n",
      "ROC AUC: 0.7090263632809506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 0.8516: 100%|██████████| 136/136 [01:30<00:00,  1.51it/s]\n",
      "100%|██████████| 30/30 [01:20<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5699577613516368  model:  transfer_learning/conflab/joint\n",
      "ROC AUC: 0.7455453171909913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 1.2951: 100%|██████████| 136/136 [02:05<00:00,  1.08it/s]\n",
      "100%|██████████| 30/30 [01:23<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7309926082365364  model:  transfer_learning/conflab/joint\n",
      "ROC AUC: 0.7039721797004566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(BS 64) loss: 1.1684:  48%|████▊     | 65/136 [01:06<01:12,  1.02s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Jose/Documents/furnace/msg3d/train.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/msg3d/train.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(config)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Jose/Documents/furnace/msg3d/train.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mstart()\n",
      "File \u001b[0;32m/mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py:451\u001b[0m, in \u001b[0;36mTrainer.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=448'>449</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39marg[\u001b[39m'\u001b[39m\u001b[39mstart_epoch\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marg[\u001b[39m'\u001b[39m\u001b[39mnum_epoch\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=449'>450</a>\u001b[0m     save_model \u001b[39m=\u001b[39m ((epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marg[\u001b[39m'\u001b[39m\u001b[39msave_interval\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marg[\u001b[39m'\u001b[39m\u001b[39mnum_epoch\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=450'>451</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(epoch, save_model\u001b[39m=\u001b[39;49msave_model)\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=451'>452</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval(epoch, save_score\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39marg[\u001b[39m'\u001b[39m\u001b[39msave_score\u001b[39m\u001b[39m'\u001b[39m], loader_name\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=453'>454</a>\u001b[0m num_params \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters() \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mrequires_grad)\n",
      "File \u001b[0;32m/mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py:309\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epoch, save_model)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=305'>306</a>\u001b[0m batch_data, batch_label \u001b[39m=\u001b[39m data[left:right], label[left:right]\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=307'>308</a>\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m--> <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=308'>309</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch_data)\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=309'>310</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/trainer.py?line=310'>311</a>\u001b[0m     output, l1 \u001b[39m=\u001b[39m output\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py:166\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=162'>163</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msgcn2(x) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgcn3d2(x), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=163'>164</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtcn2(x)\n\u001b[0;32m--> <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=165'>166</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msgcn3(x) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgcn3d3(x), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=166'>167</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtcn3(x)\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=168'>169</a>\u001b[0m out \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py:100\u001b[0m, in \u001b[0;36mMultiWindow_MS_G3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=97'>98</a>\u001b[0m out_sum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=98'>99</a>\u001b[0m \u001b[39mfor\u001b[39;00m gcn3d \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgcn3d:\n\u001b[0;32m--> <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=99'>100</a>\u001b[0m     out_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m gcn3d(x)\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=100'>101</a>\u001b[0m \u001b[39m# no activation\u001b[39;00m\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out_sum\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py:61\u001b[0m, in \u001b[0;36mMS_G3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=58'>59</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min1x1(x)\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=59'>60</a>\u001b[0m \u001b[39m# Construct temporal windows and apply MS-GCN\u001b[39;00m\n\u001b[0;32m---> <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=60'>61</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgcn3d(x)\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=62'>63</a>\u001b[0m \u001b[39m# Collapse the window dimension\u001b[39;00m\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/msg3d.py?line=63'>64</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(N, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_channels_out, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size, V)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jose/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/Jose/Documents/furnace/msg3d/model/ms_gtcn.py:99\u001b[0m, in \u001b[0;36mSpatialTemporal_MS_GCN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/ms_gtcn.py?line=95'>96</a>\u001b[0m N, C, T, V \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape    \u001b[39m# T = number of windows\u001b[39;00m\n\u001b[1;32m     <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/ms_gtcn.py?line=97'>98</a>\u001b[0m \u001b[39m# Build graphs\u001b[39;00m\n\u001b[0;32m---> <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/ms_gtcn.py?line=98'>99</a>\u001b[0m A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA_scales\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdtype)\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdevice) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA_res\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/ms_gtcn.py?line=100'>101</a>\u001b[0m \u001b[39m# Perform Graph Convolution\u001b[39;00m\n\u001b[1;32m    <a href='file:///mnt/c/Users/Jose/Documents/furnace/msg3d/model/ms_gtcn.py?line=101'>102</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config)\n",
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
